{"job title": "Data Engineer", "company": "Jellyfish", "city state": "\u2013 US-VA-Reston", "rating": "4.5", "job description": "Overview<br><br>Jellyfish, delivers digital marketing solutions across the world for a host of impressive brands from their offices in the US, Europe, and South Africa. The agency\u2019s award-winning combination of technology and talent help it to deliver paid media, UX, SEO, social media, analytics, optimization, creative and development solutions.\n<br><br>\nWe at Jellyfish appreciate the value of data within ours and client\u2019s business. We generate more data than ever before but we recognise that clean and meaningful data streamed at a rate which can give us a competitive edge is the key. Our Data Engineers are key to activating our innovative solutions and the role requires an individual who can work with other analysts to create solutions which integrate with our advertising technology stack.<br><br>Responsibilities\n\n\n<ul>\n\n <li>Responsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs. Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery</li>\n<li>Responsible for the management of multiple processes and applications, performance reporting and error checking</li>\n<li>Responsible for the management of all data created within client applications, the structure of data held and the views of data created</li>\n<li>Responsible for recommending the correct technologies to be used and in the most cost effective manner</li>\n<li>Responsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance</li>\n<li>Provide thought leadership with regards to best practice and use of the google cloud platform</li>\n</ul>\n\nQualifications\n\n\n<ul>\n\n <li>BS Degree</li> \n\n<li>Data Engineering/ BI Development/ Data Warehousing experience. Knowledge of server-less infrastructure beneficial</li>\n<li>Ability to scope a project based on a technical brief and work with the DevOps and QA teams to provide a detailed project plan including:</li></ul>\n\n<ul>\n\n\n\n<ul>\n\n <li>Data Flow Diagrams for process flow</li>\n<li>Database Schemas &amp; Normalisation</li>\n<li>Recommended software / plugins / architecture</li>\n<li>Scalable environment architecture suggestions</li>\n<li>Hosting, storage, load balancing and caching suggestions</li>\n<li>Performance considerations</li>\n<li>Security considerations</li>\n<li>Assumptions &amp; Exclusions</li>\n<li>A complete and accurate estimate for the project</li></ul>\n\n</ul>\n\n\n\n<ul>\n\n <li>Ability to assess new business and respond with a full list of targeted questions to ensure accurate estimates are created</li>\n<li>Ability to research solutions to technical problems</li>\n<li>Experience scheduling/automating scripts</li>\n<li>Experience with streaming data beneficial</li>\n<li>Experience on Linux command line and Bash scripting</li>\n<li>Experience with Git/GitHub</li>\n<li>Experience with Amazon/Google Cloud services. Experience with Dataflow, Google PubSub or other queuing software beneficial</li>\n<li>Good experience of parsing data formats such as XML/JSON and using 3rd party API\u2019s</li>\n<li>Experience with Curl / similar beneficial</li>\n<li>Solid Python programming skills. Java / other languages beneficial</li>\n<li>Strong SQL experience</li>\n<li>Experience in using Key/Value or Document Stores such as DocumentDB, BigTable, NoSQL, MongoDB, Hadoop</li>\n<li>Basic experience with Tensorflow. CloudML/Spark/SparkML Beneficial</li>\n<li>An understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholders</li>\n<li>Must have experience of building robust pipelines and data environments to support database or machine learning based applications</li>\n</ul>"}
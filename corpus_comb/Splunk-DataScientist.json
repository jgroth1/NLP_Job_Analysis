{"job title": "Data Scientist", "company": "Splunk", "city state": "\u2013 Boulder, CO, United States", "rating": "3.8", "job description": "Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and seek to deliver the best experience for our customers. At Splunk, we\u2019re committed to our work, customers, having fun and most importantly to each other\u2019s success. Learn more about Splunk careers and how you can become a part of our journey!\n<br><br>\nThe Data Scientist role involves working on all the stages of the data science pipeline, including acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms, and also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLlib.<br><br><strong>Key Responsibilities:</strong>\n\n<ul>\n<li>You will become an expert on the product data, including how it is collected and processed</li><li>You will explore the data and answer questions about the data to improve our understanding of the potential of the data</li><li>You will closely interact with product management and engineering to derive requirements for what solutions should be implemented in the product</li><li>You will rapidly prototype, and evaluate statistical and machine learning solutions</li><li>You will collaborate with engineering to implement these solutions in production</li><li>You will communicate your results and explain your solutions to technical and non-technical stakeholders</li>\n</ul>\n\n<strong>Required Experience/Skills &amp; Education:\n<br>\n</strong>\n\n<ul>\n<li>You have experience with Python scikit-learn, Spark/MLlib, or an equivalent framework \u2013 required</li><li>You have the ability to code in Python, Java or Scala - required</li><li>You have the ability to evaluate and tune statistical and machine learning solutions \u2013 required</li><li>You have experience working with large datasets, preferably using tools like SQL, Spark, Hadoop, MapReduce, Pig, or Hive \u2013 preferred</li>\n</ul>\n\n<strong>What We Offer You:\n<br>\n</strong>\n\n<ul>\n<li>A constant stream of new things for you to learn. We're always growing into new areas, bringing in open source projects and contributing back, and exploring new technologies.</li><li>A set of extraordinarily talented and dedicated peers, all the way from engineering and QA to product management and customer support.</li><li>A stable, collaborative and supportive work environment.</li><li>We don't expect people to work 12-hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an exceptional environment.</li>\n</ul>\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status\n<br><br>\n<strong>Note: To apply for this job, submit your application by clicking on the <u>Apply Now</u> button on this page</strong>"}
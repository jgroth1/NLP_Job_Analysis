{"job title": "Data Scientist", "company": "DISH Network Corporation", "city state": "\u2013 Englewood, CO", "rating": "2.8", "job description": "Summary\n<br><br>\nSling TV L.L.C. provides an over-the-top television experience on TVs, tablets, gaming consoles, computers, smartphones and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, T-Mobile, Sprint, Roku, Samsung, Netflix, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, Fox, NBC, HBO, AMC, A&amp;E, EPIX, Cinemax, Starz, NFL Network, NFL Networks, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, Univision, and more. For spanish-speaker customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the U S. Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.\n<br><br>\nSling TV is the #1 Live TV Streaming Service\n<br><br>\n(Based on the number of OTT households as reported by comScore as of April 2017)\n<br><br>\nSling TV is a next-generation service that meets the entertainment needs of today's contemporary viewers. Visit www.Sling.com.\n<br><br>\nJob Duties and Responsibilities\n<br><br>\nAbout the position\n<br><br>\nOur mission is to build the next generation, web scale platform for Sling TV. Our environment is\n\n\n<ul>\n<li>Complex</li>\n<li>Highly elastic</li>\n<li>Based on some of the latest and greatest cloud native technologies</li>\n<li>Very fast paced</li>\n</ul>\n\nYour team will be\n\n\n<ul>\n<li>Enabling a proper enterprise Data Lake in AWS</li>\n<li>Building models and tools to get value out of the mass amounts of data we have in our environment</li>\n<li>Enabling the best customer experience possible</li>\n</ul>\n\nIn order to be successful in this role, you will need to be\n\n\n<ul>\n<li>Highly motivated, driven&amp;hard working</li>\n<li>Not afraid to fail and comfortable working independently and with a team</li>\n<li>Comfortable working with massive datasets in real time and batch processing with superior analytics skills</li>\n<li>Comfortable talking to and working with Senior Executives</li>\n<li>Apply data mining techniques, do statistical analysis, and build high quality prediction systems integrated with our product. Doing ad-hoc analysis and presenting results in a clear manner.</li>\n<li>Processing, cleansing, and verifying the integrity of data used for analysis</li>\n<li>Enhancing data collection procedures to include information that is relevant for building analytic systems</li>\n<li>Data mining using state-of-the-art methods. Create automated anomaly detection systems and constant tracking of its performance.</li>\n<li>A team player. We have a great group of diverse folks working together in harmony. Big egos and \"super heroes\" need not apply.</li>\n<li>Real-time machine learning</li>\n</ul>\n\nSkills - Experience and Requirements\n<br><br>\n<strong>Basic Requirements:</strong>\n<br><br>\n<strong>A successful Data Scientist will:</strong>\n\n\n<ul>\n<li>Be available to work onsite out of our American Fork, UT or Englewood, CO offices</li>\n<li>Have a 4-year college degree in Computer Science / Information Technology, master's degree is preferred or equivalent professional experience</li>\n<li>10+ years professional enterprise experience</li>\n<li>Open to occasional travel for quarterly planning meetings and or other key workshops</li>\n</ul>\n\n<strong>Technologies in our environment:</strong>\n<br><br>\nHere are some of the key technologies that make up our environment. While we do not expect you to have a detailed understanding of each, the more of these you are familiar with the better.\n\n\n<ul>\n<li>ELK Stack / HDFS / Hadoop / Hive</li>\n<li>Linux</li>\n<li>AWS Big Data Tools: S3, Kinesis, Red Shift, Athena,</li>\n<li>Java, Python, R, SQL</li>\n<li>Machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, h20.ai, etc.</li>\n<li>Artificial Intelligence</li>\n<li>Predictive Analytics</li>\n<li>Tableau or other visualization tools</li>\n<li>Kafka / Confluent</li>\n<li>CI / CD and Cloud Native Computing (Docker, Kubernetes, Consul, Vault)</li>\n</ul>\n\n<strong>#LI-SLING2</strong>"}
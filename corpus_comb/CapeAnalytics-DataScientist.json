{"job title": "Data Scientist", "company": "Cape Analytics", "city state": "\u2013 Mountain View, CA", "rating": "5.0", "job description": "<div>Cape Analytics uses AI and geospatial imagery to provide instant property intelligence for buildings across the United States. Cape Analytics enables insurers and other property stakeholders to access valuable property attributes at time of underwritingwith the accuracy and detail that traditionally required an on-site inspection, but with the speed and coverage of property record pre-fill. Founded in 2014, Cape Analytics is backed by leading venture firms and innovative insurers, and comprised of computer vision and risk analysis experts.</div><div><br></div><div>We believe:</div><div><br></div><div>*Talent is critical, but best when tempered with humility</div><div>*Self-motivation leads to the best outcomes</div><div>*Open, direct communication is a sign of respect</div><div>*Teamwork drives success</div><div>*Having fun together is an important part of the job</div><div><br></div><div>***Cape Analytics is an E-verify participant.***</div><div><br></div><div><b>Positions Summary: </b></div><div><br></div><div>We are looking for a Data Scientist with a scientific approach who has strong expertise in data analysis, statistics, programming, and machine learning to join our Data Science team. You will collaborate with Data Scientists, Computer Vision/Machine Learning Engineers, Data Engineers, and members across Software Engineering, Product, and Sales teams to build robust, scalable machine learning models for identification and annotation of the built world. Additionally, you will develop expertise in ground truth generation, model performance analysis, iterative model development, and unsupervised mapping of the feature space to bring scientific rigor, scalability, and robust performance to our core product offerings.</div>What You'll Do:<ul><li>Develop scientifically rigorous, creative methodologies to continuously improve our machine learning models</li><li>Incorporate machine learning and data-driven decisioning into the core of our infrastructure</li><li>Contribute to design and automation of model training, model post-processing and evaluation pipelines at scale</li><li>Leverage the extensive data generated by Cape in addition to data from external sources to generate structured knowledge about our feature space</li><li>Present your results internally and externally; </li><li>Defend your methodology and incorporate feedback from internal teams as well as customers.</li><li>Improve model performance by identifying failure modes using supervised and unsupervised learning techniques</li><li>Ideate and implement data-driven methodologies to help scale model performance across geographical, climatic, and temporal dimensions</li><li>Implement automated solutions for ensuring data quality and delivery</li><li>Explore and mine new data sources that will help optimize and validate our models</li><li>Link model capabilities to market needs by customizing models, designing and running validation studiesContribute to peer mentorship, knowledge bases, and skills transfer</li></ul>Skills/Requirements:<ul><li>Graduate degree in a STEM field (PhD preferred but not required) and 1-3 years of hands-on industry experience</li><li>Solid knowledge of statistical techniques, including hypothesis testing, statistical sampling, significance testing, statistical inference, maximum likelihood estimation, and experimental design, among others. </li><li>Mastery of, supervised and unsupervised algorithms and their implementations, machine learning concepts including regularization, learning curves, optimizing hyperparameters, cross-validation, among others.</li><li>Advanced knowledge and significant programming experience in Python programming or other scripting language including relevant libraries like numpy, pandas, SciPy, matplotlib</li><li>Familiarity with the Linux environment including shell scripting, Git and tools for reproducibility (e.g. virtual environments, Docker )</li><li>Demonstrated expertise in building data tools for ETL and data analysis</li><li>Experience in building meaningful data visualizations using at least one scripting-based visualization tool such as matplotlib, d3.js or bokeh</li><li><b>Nice to haves: </b>Experience designing data schemas and extracting data from SQL and NoSQL databases. Experience with GIS systems. Experience with modern data technologies, e.g. Spark, Tensorflow, Jupyter Notebook, DockerExperience with cloud computing on AWS or GCP</li></ul><div><br></div>"}
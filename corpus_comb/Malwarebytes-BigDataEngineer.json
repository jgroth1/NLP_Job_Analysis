{"job title": "Big Data Engineer", "company": "Malwarebytes", "city state": "\u2013 Santa Clara, California", "rating": "4.0", "job description": "<strong>Who We Are:</strong>\n<br><br>\nMalwarebytes is the next-gen cybersecurity company that millions worldwide trust. Malwarebytes proactively protects people and businesses against dangerous threats such as malware, ransomware, and exploits that escape detection by traditional antivirus solutions. The company's flagship product combines advanced heuristic threat detection with signatureless technologies to detect and stop a cyberattack before damage occurs. More than 10,000 businesses worldwide use, trust, and recommend Malwarebytes. Founded in 2008, the company is headquartered in California, with offices in Europe and Asia, and a global team of threat researchers and security experts\n<br>\nWe've created a fantastic culture that our employees love and were recently named in the top 10 of Fortune Magazine's Great Place to Work list. We're growing fast and are looking for some great people to join us.\n<br><br>\n<strong>Who We Need:</strong>\n<br><br>\nMalwarebytes is seeking a top tier candidate for the Senior Data Engineer role. The position will build a world class, best practice, reliable and cost effective corporate data architecture and platform. The Senior Data Engineer will build a data infrastructure consuming data from various internal and external sources. This infrastructure will be built on Hadoop and AWS and industry leading analytics and data science tools. The Senior Data Engineer will implement important data concepts like SQL transformations, aggregation, normalization, file transformation, batch processing, query tuning, physical modeling and appropriate metadata. A key goal will be to expose the unified data as a corporate data service layer. This is a great opportunity to build a world-class data architecture from the ground up.\n<br><br>\n<strong>What You'll Do:</strong>\n<br><br>\nBuilding Data pipelines on Big Data infrastructure in Cloud\n<br>\nData induction and transformation\n<br>\nETL coding in Hadoop\n<br>\nProcess scheduling in for batch\n<br>\nBuild out a fault tolerant ETL architecture\n<br>\nBuild out a data quality monitoring framework\n<br>\nCreate self-healing ETL and load jobs\n<br>\nQuery tuning in Hive/Spark/HDFS/RDBMS\n<br>\nPhysical modeling\n<br><br>\n<strong>Skills You'll Need to Have:</strong>\n<br><br>\nRock star SQL\n<br>\nExpert level query tuning in any MPP databases (like Teradata, Redshift etc.)\n<br>\nDamn good Unix scripting\n<br>\nMacGyver is jealous of your data skills.\n<br>\nExpert with workload automation - AutoSys, Control-M, etc.\n<br>\nExpert on 1 or more MPP databases - Exadata, Vertica, Teradata, Redshift, etc.\n<br>\n5 years minimum experience with building complex data pipelines\n<br>\nComfortable in a mature software engineering environment\n<br>\nKnowledgeable about key design patterns in data warehousing and big data\n<br>\nDeep knowledge about fault tolerant and decoupled architecture\n<br>\nData modeling experience logical and physical\n<br>\nJava/Scala. These are nice to have.\n<br>\nAngry people make us angry.\n<br>\nBachelor's degree in a technical/scientific field or equivalent work experience\n<br><br>\n<strong>What We Offer:</strong>\n<br><br>\nAn opportunity to do something great for yourself and the world\n<br>\nA great work environment that supports growth and development\n<br>\nCompetitive compensation and benefit packages\n<br>\n401(k) matching program\n<br>\nOpen time off policy\n<br>\nStocked kitchen with healthy (and some unhealthy) drinks, snacks, fruit and lunch options\n<br>\nA company who enjoys having fun; holiday and summer parties, sporting events and lots of other great stuff"}
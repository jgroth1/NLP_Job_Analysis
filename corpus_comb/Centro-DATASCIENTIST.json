{"job title": "DATA SCIENTIST", "company": "Centro", "city state": "\u2013 Chicago", "rating": "3.7", "job description": "We\u2019re here to ensure the advertising industry and the people in it are healthy and engaging positively and effectively with those around them. We\u2019re here, ultimately, to improve the lives of people working in the media industry. And we take our responsibility seriously.\n<br><br>\nCentro\u2019s technology focuses on improving and streamlining digital media logistics for online advertising. We\u2019re here to ensure the advertising industry and the people in it are healthy and engaging positively and effectively with those around them. We\u2019re here, ultimately, to improve the lives of people working in the media industry. And we take our responsibility seriously.\n<br><br>\n<strong>ABOUT THE TEAM</strong>\n<br><br>\nThe Data Science team at Centro focuses on extracting actionable insights from data and building Machine Learning algorithms using large amounts of data. We aim to derive meaning from our data enabling us to run our business better and equip our clients to advertise smarter. As part of our Data Science team, you will be working with product managers, engineers, and business stakeholders to bridge the gap between raw data and making informed decisions.\n<br><br>\n<strong>ABOUT THE ROLE</strong>\n<br><br>\nWe are looking for a Data Scientist who has experience in building machine learning algorithms in distributed environments such as Amazon EMR. The ideal candidate will have a passion for discovering patterns from large data sets and working with internal stakeholders to understand the business problems. The candidate will have experience working with distributed data processing tools and infrastructure including MapReduce, Hadoop, Hive, Spark, AWS and EMR.\n<br><br>\n<strong>CORE RESPONSIBILITIES</strong>\n<ul>\n<li>Understand pros and cons of different machine learning tools (e.g. MLlib, scikit-learn, Amazon SageMaker) and recommend which one to use for a given problem</li><li>Analyze steps involved in training a machine learning algorithm and break down into steps that can process terabytes of data in a distributed environment. This will involve analyzing vast amounts of data, generating features that are relevant to the problem, and running Spark jobs to pre-process the data that can be used to train the learning algorithm</li><li>Analyze results from these steps and fine-tune model parameters iteratively to improve efficiency and accuracy</li><li>Compile final outputs of the algorithms and present to stakeholders in a way that is comprehensible by non-technical audience</li><li>Write complex queries in relational databases and Big Data (Spark/Hadoop) clusters</li><li>Understand the business logic behind the data structure and nuances of the data. Understand the relationships among disparate data sources including where they come from and what they represent</li><li>Understand behind-the-scenes steps of machine learning algorithms and do not treat them as black boxes. Know pros and cons of different machine learning practices. Select the most appropriate algorithm for a given task and explain why a particular algorithm is better than others to solve the problem</li><li>Create data visualizations to tell the story from the data. Understand what types of visualizations are appropriate for the audience</li><li>Collaborate with Product Operations team to set up environments needed for the data science team. Communicate effectively on what is needed and brainstorm with them to explore the best solution for a given problem</li><li>Collaborate with Product, Engineering and QA teams in productizing proof-of-concept machine learning algorithms</li><li>Possess business savviness and understand the business problem before formulating solutions. Identify which data is relevant to solve the problem and propose solutions</li><li>Proactively seek opportunities to help predict the outcomes of business decisions and mitigate potential threats to the business. Communicate the benefits of the use of data in making informed decisions to business stakeholders. Manage expectations and explain existing technical limitations in a manner all stakeholders can understand</li>\n</ul>\n<strong>YOU ARE RIGHT FOR THE JOB IF:</strong>\n<ul>\n<li>You have at least 2 years of experience working with machine learning algorithms in a distributed environment using large-scale data processing tools</li><li>Your education background and relevant work experience demonstrate a mixture of math, statistics, and data engineering</li><li>You are able to code in Python and R</li><li>You can extract data on your own and prepare a large data set to train a machine learning algorithm</li><li>You feel comfortable working with data that is sometimes incomplete, or messy\u2026or both.</li><li>You don\u2019t make assumptions about the data yourself. Instead, you are willing to work with others to get a clear understanding of the context around the data</li><li>You possess business acumen and curiosity to learn Centro\u2019s business operations</li><li>You don\u2019t limit yourself to how things are done today. You instead focus on the best ways to create value</li>\n</ul>\n<strong>Bonus item:</strong>\n<ul>\n<li>You have experience working in Ad Tech and are familiar with data from ad servers such as DoubleClick</li>\n</ul>\n<strong>Centro is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of race, gender, age, disability or any other basis protected under the law.</strong>"}